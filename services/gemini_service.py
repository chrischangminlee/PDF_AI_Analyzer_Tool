# gemini_service.py - ë°°ì¹˜ ë¶„ì„ ë° ê²€ì¦ ê¸°ëŠ¥

import io, os, tempfile, json, time
import streamlit as st
from PyPDF2 import PdfReader, PdfWriter
import google.generativeai as genai

# ëª¨ë¸ ìƒìˆ˜
GEMINI_MODEL = "gemini-2.5-flash"

def call_gemini_with_retry(model, content, max_retries=3, base_delay=1, status_placeholder=None):
    """Gemini API í˜¸ì¶œì„ ì¬ì‹œë„ ë¡œì§ê³¼ í•¨ê»˜ ì‹¤í–‰"""
    for attempt in range(max_retries):
        try:
            # API í˜¸ì¶œ ì „ ëŒ€ê¸° (rate limiting)
            if attempt > 0:
                delay = base_delay * (2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                if status_placeholder:
                    status_placeholder.info(f"â³ API í˜¸ì¶œ ëŒ€ê¸° ì¤‘... ({delay}ì´ˆ)")
                time.sleep(delay)
            
            response = model.generate_content(content)
            return response.text.strip()
            
        except Exception as e:
            error_msg = str(e)
            
            if "429" in error_msg or "quota" in error_msg.lower():
                # í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ
                if attempt < max_retries - 1:
                    if status_placeholder:
                        status_placeholder.warning(f"âš ï¸ API í• ë‹¹ëŸ‰ ì´ˆê³¼. 30ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„... ({attempt + 1}/{max_retries})")
                    time.sleep(30)
                else:
                    if status_placeholder:
                        status_placeholder.error("âŒ API í• ë‹¹ëŸ‰ì´ ì™„ì „íˆ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    raise Exception("QUOTA_EXHAUSTED")
            else:
                # ë‹¤ë¥¸ ì˜¤ë¥˜
                if attempt < max_retries - 1:
                    if status_placeholder:
                        status_placeholder.warning(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨. 5ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„... ({attempt + 1}/{max_retries})")
                    time.sleep(5)
                else:
                    raise e
    
    raise Exception("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")

def parse_page_info(gemini_response):
    """ê°œì„ ëœ í˜ì´ì§€ ì •ë³´ íŒŒì‹± - JSON í˜•ì‹ ì‚¬ìš©"""
    pages, page_info = [], {}
    
    try:
        # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸
        if not gemini_response or not gemini_response.strip():
            st.warning("âš ï¸ Gemini ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return pages, page_info
            
        if "```json" in gemini_response:
            json_str = gemini_response.split("```json")[1].split("```")[0].strip()
        elif "{" in gemini_response and "}" in gemini_response:
            start = gemini_response.find("{")
            end = gemini_response.rfind("}") + 1
            json_str = gemini_response[start:end]
        else:
            st.warning("âš ï¸ JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ì¡´ íŒŒì‹± ë°©ì‹ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            return parse_page_info_legacy(gemini_response)
        
        data = json.loads(json_str)
        
        # í˜ì´ì§€ê°€ ì—†ëŠ” ê²½ìš° í™•ì¸
        if not data.get("pages"):
            st.info("â„¹ï¸ ê´€ë ¨ í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pages, page_info
            
        for item in data.get("pages", []):
            page_num = item.get("page_number")
            if page_num:
                # page_numì´ listì¸ ê²½ìš° ì²« ë²ˆì§¸ ê°’ë§Œ ì‚¬ìš©
                if isinstance(page_num, list):
                    page_num = page_num[0] if page_num else None
                if page_num and isinstance(page_num, (int, str)):
                    try:
                        page_num = int(page_num)
                        pages.append(page_num)
                        page_info[page_num] = {
                            'page_response': item.get('answer', ''),
                            'relevance': item.get('relevance', 'í•˜')
                        }
                    except (ValueError, TypeError):
                        continue
                
    except (json.JSONDecodeError, KeyError) as e:
        st.warning(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        st.text("Gemini ì‘ë‹µ:")
        st.code(gemini_response[:500] + "..." if len(gemini_response) > 500 else gemini_response)
        return parse_page_info_legacy(gemini_response)
    
    return pages, page_info

def parse_page_info_legacy(gemini_response):
    """ê¸°ì¡´ íŒŒì´í”„ í˜•ì‹ íŒŒì‹± (í´ë°±ìš©)"""
    pages, page_info = [], {}
    for line in gemini_response.strip().split('\n'):
        if '|' in line:
            try:
                parts = line.strip().split('|')
                if len(parts) == 3:
                    physical_page = int(parts[0].strip())
                    page_response = parts[1].strip()
                    relevance = parts[2].strip()
                    pages.append(physical_page)
                    page_info[physical_page] = {
                        'page_response': page_response, 
                        'relevance': relevance
                    }
            except (ValueError, IndexError):
                continue
    return pages, page_info

def split_pdf_for_batch_analysis(pdf_bytes, batch_size=10):
    """PDFë¥¼ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜"""
    reader = PdfReader(io.BytesIO(pdf_bytes))
    total_pages = len(reader.pages)
    batches = []
    
    for start_idx in range(0, total_pages, batch_size):
        end_idx = min(start_idx + batch_size, total_pages)
        
        # ë°°ì¹˜ PDF ìƒì„±
        writer = PdfWriter()
        for i in range(start_idx, end_idx):
            writer.add_page(reader.pages[i])
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            writer.write(tmp)
            tmp_path = tmp.name
        
        batches.append({
            'path': tmp_path,
            'start_page': start_idx + 1,
            'end_page': end_idx,
            'pages': list(range(start_idx + 1, end_idx + 1))
        })
    
    return batches

def analyze_pdf_batch(batch_path, refined_prompt, batch_info, status_placeholder=None):
    """ë‹¨ì¼ ë°°ì¹˜ PDF ë¶„ì„"""
    # ë°°ì¹˜ íŒŒì¼ì„ Geminiì— ì—…ë¡œë“œ
    batch_file = genai.upload_file(batch_path)
    
    prompt = f"""
    ì´ PDFëŠ” ì „ì²´ ë¬¸ì„œì˜ {batch_info['start_page']}í˜ì´ì§€ë¶€í„° {batch_info['end_page']}í˜ì´ì§€ê¹Œì§€ë§Œ í¬í•¨í•©ë‹ˆë‹¤.

    ì¤‘ìš”: ê° í˜ì´ì§€ì˜ ì¢Œì¸¡ ìƒë‹¨ì— í‘œì‹œëœ ë²ˆí˜¸ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•˜ê³  ì‚¬ìš©í•˜ì„¸ìš”.

    ## ì‚¬ìš©ì ì§ˆë¬¸
    {refined_prompt}

    ## ì—„ê²©í•œ ê´€ë ¨ì„± íŒë‹¨ ê¸°ì¤€
    âš ï¸ **ë§¤ìš° ì¤‘ìš”**: ë‹¤ìŒ ê¸°ì¤€ì„ ì—„ê²©íˆ ì ìš©í•˜ì„¸ìš”.

    **ìƒ (ì§ì ‘ ë‹µë³€)**  
    - í˜ì´ì§€ ì•ˆì— **ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ëª…ì‹œì Â·ì§ì ‘ì  ë‹µë³€ ë¬¸ì¥**ì´ ì¡´ì¬í•¨  
    - ì§ˆë¬¸ í•µì‹¬ í‚¤ì›Œë“œë¿ ì•„ë‹ˆë¼ **ë‹µë³€ ë‚´ìš© ìì²´**ê°€ í¬í•¨ë˜ì–´ ìˆìŒ  
    - â€˜answerâ€™ í•„ë“œì— í•´ë‹¹ ë¬¸ì¥(ë˜ëŠ” í•µì‹¬ ìš”ì•½)ì„ **30ì ì´ë‚´**ë¡œ ì…ë ¥  
    - ìœ„ ì¡°ê±´ì„ ëª¨ë‘ ì¶©ì¡±í•˜ì§€ ëª»í•˜ë©´ â€˜ìƒâ€™ìœ¼ë¡œ ë¶„ë¥˜í•˜ì§€ ë§ ê²ƒ

    **ì¤‘ (ê°„ì ‘ ê´€ë ¨)**  
    - ì§ˆë¬¸ê³¼ ë°€ì ‘í•œ ë°°ê²½Â·ë§¥ë½Â·ìƒìœ„/í•˜ìœ„ ê°œë…ì„ ë‹¤ë£¸  
    - ì§ì ‘ì ì¸ ë‹µì€ ì—†ì§€ë§Œ ë¬¸ì œ í•´ê²°ì— ì‹¤ì§ˆì ìœ¼ë¡œ ë„ì›€ì´ ë˜ëŠ” ì •ë³´ í¬í•¨  
    - â€˜answerâ€™ í•„ë“œëŠ” **ë¹ˆ ë¬¸ìì—´("")**ë¡œ ë‘ê±°ë‚˜ ìƒëµ

    **í•˜ (ê´€ë ¨ ì—†ìŒ)** â€“ ê²°ê³¼ì—ì„œ **ì œì™¸**  
    - ì§ˆë¬¸ê³¼ ì „í˜€ ë¬´ê´€í•˜ê±°ë‚˜ í‚¤ì›Œë“œê°€ ìš°ì—°íˆ ë“±ì¥í•˜ëŠ” ìˆ˜ì¤€  
    - ëª©ì°¨, ì„œë¬¸, ë¶€ë¡ ë“±

    ## ë¶„ì„ ì§€ì‹œì‚¬í•­
    1. ê° í˜ì´ì§€ë¥¼ **ë…ë¦½ì ìœ¼ë¡œ** ë¶„ì„  
    2. í˜ì´ì§€ ì¢Œì¸¡ ìƒë‹¨ ë²ˆí˜¸ í™•ì¸  
    3. **ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ ë‹µë³€ ë¬¸ì¥ì´ ìˆìœ¼ë©´** 30ì ì´ë‚´ë¡œ ë°œì·ŒÂ·ìš”ì•½í•˜ì—¬ `answer`ì— ì…ë ¥  
    4. **â€˜ìƒâ€™ ë˜ëŠ” â€˜ì¤‘â€™**ì— í•´ë‹¹í•˜ëŠ” í˜ì´ì§€ë§Œ ê²°ê³¼ì— í¬í•¨  
    - **â€˜ìƒâ€™**: â‘¢ì˜ ë‹µë³€ì´ ì¡´ì¬í•˜ë©° ì¡°ê±´ ì¶©ì¡±  
    - **â€˜ì¤‘â€™**: ë‹µë³€ì€ ì—†ì§€ë§Œ ìœ ì˜ë¯¸í•œ ê°„ì ‘ ì •ë³´ í¬í•¨  
    5. í™•ì‹ ì´ ì—†ìœ¼ë©´ ì œì™¸(ì˜¤íƒ ë°©ì§€)

    ## ì‘ë‹µ í˜•ì‹
    ê´€ë ¨ì„±ì´ ë†’ì€ í˜ì´ì§€ë§Œ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

    ```json
    {{
        "pages": [
            {{
                "page_number": [ì¢Œì¸¡ ìƒë‹¨ì˜ ì‹¤ì œ í˜ì´ì§€ ë²ˆí˜¸],
                "answer": "[ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ ë‹µë³€ (30ì ì´ë‚´) ë˜ëŠ” ë¹ˆ ë¬¸ìì—´]",
                "relevance": "[ìƒ/ì¤‘]"
            }}
        ]
    }}
    ```
    
    âš ï¸ ê´€ë ¨ì„±ì´ ë‚®ì€ í˜ì´ì§€ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”!
    """
    
    model = genai.GenerativeModel(GEMINI_MODEL)
    return call_gemini_with_retry(model, [batch_file, prompt], status_placeholder=status_placeholder)

def enhance_user_prompt(user_prompt, status_placeholder=None):
    """ì‚¬ìš©ìì˜ ì´ˆê¸° í”„ë¡¬í”„íŠ¸ë¥¼ ë” ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ê°œì„ """
    try:
        if status_placeholder:
            status_placeholder.info("ğŸ” ì§ˆë¬¸ ë¶„ì„ ì¤‘...")
        
        prompt = f"""
ë‹¹ì‹ ì€ PDF ë¬¸ì„œ ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ê°œì„  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬, PDFì—ì„œ ì •í™•í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë” ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ê°œì„ í•´ì£¼ì„¸ìš”.

ì›ë³¸ ì§ˆë¬¸: {user_prompt}

ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ì§ˆë¬¸ì„ ê°œì„ í•˜ì„¸ìš”:
1. ëª¨í˜¸í•œ í‘œí˜„ì„ êµ¬ì²´ì ìœ¼ë¡œ ë³€ê²½
2. ê´€ë ¨ ìš©ì–´ë‚˜ ë™ì˜ì–´ ì¶”ê°€
3. ì°¾ê³ ì í•˜ëŠ” ì •ë³´ì˜ ìœ í˜• ëª…í™•í™” (ì •ì˜, ì ˆì°¨, ì¡°ê±´, ê¸ˆì•¡ ë“±)
4. ë¶ˆí•„ìš”í•œ ì •ì¤‘í•œ í‘œí˜„ ì œê±° ("ì•Œë ¤ì¤˜", "ë¶€íƒí•´" ë“±)

ê°œì„ ëœ ì§ˆë¬¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
"""
        
        model = genai.GenerativeModel(GEMINI_MODEL)
        enhanced_prompt = call_gemini_with_retry(model, prompt, max_retries=2, base_delay=1)
        
        if status_placeholder:
            status_placeholder.success(f"âœ… ì§ˆë¬¸ ë¶„ì„ ì™„ë£Œ: {enhanced_prompt}")
        
        return enhanced_prompt.strip()
        
    except Exception as e:
        if status_placeholder:
            status_placeholder.warning("âš ï¸ ì§ˆë¬¸ ê°œì„  ì‹¤íŒ¨, ì›ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        return user_prompt

def find_relevant_pages_with_gemini(user_prompt, pdf_bytes=None, status_placeholder=None):
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ PDF ë¶„ì„"""
    all_pages = []
    all_page_info = {}
    
    if pdf_bytes:
        # í”„ë¡¬í”„íŠ¸ ê°œì„ 
        refined_prompt = enhance_user_prompt(user_prompt, status_placeholder)
        
        # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì„¸ì…˜ì— ì €ì¥
        st.session_state.refined_prompt = refined_prompt
        
        # PDFë¥¼ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ë¶„ì„
        batches = split_pdf_for_batch_analysis(pdf_bytes, batch_size=10)
        
        progress_bar = st.progress(0)
        for idx, batch in enumerate(batches):
            progress_bar.progress((idx + 1) / len(batches))
            
            try:
                # ë°°ì¹˜ê°„ ëŒ€ê¸° ì‹œê°„ ì œê±° (Paid API ì‚¬ìš©)
                
                # í˜„ì¬ ë°°ì¹˜ ì§„í–‰ìƒí™© í‘œì‹œ
                if status_placeholder:
                    status_placeholder.info(f"ğŸ¤– ë°°ì¹˜ {idx + 1}/{len(batches)} ë¶„ì„ ì¤‘... (í˜ì´ì§€ {batch['start_page']}-{batch['end_page']})")
                
                # ë°°ì¹˜ ë¶„ì„ (ë‚´ë¶€ì—ì„œ ì—…ë¡œë“œ ì²˜ë¦¬)
                batch_response = analyze_pdf_batch(batch['path'], refined_prompt, batch, status_placeholder)
                
                # ê²°ê³¼ íŒŒì‹±
                pages, page_info = parse_page_info(batch_response)
                
                # ì „ì²´ ê²°ê³¼ì— ë³‘í•©
                all_pages.extend(pages)
                all_page_info.update(page_info)
                
            except Exception as e:
                # API í• ë‹¹ëŸ‰ ì†Œì§„ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨
                if "QUOTA_EXHAUSTED" in str(e):
                    if status_placeholder:
                        status_placeholder.error("âŒ API í• ë‹¹ëŸ‰ì´ ì†Œì§„ë˜ì–´ ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    progress_bar.empty()
                    # í• ë‹¹ëŸ‰ ì†Œì§„ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜ (ë¶€ë¶„ ê²°ê³¼ X)
                    return [], {}
                else:
                    if status_placeholder:
                        status_placeholder.warning(f"âš ï¸ ë°°ì¹˜ {idx + 1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                if os.path.exists(batch['path']):
                    os.unlink(batch['path'])
        
        progress_bar.empty()
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_pages = list(dict.fromkeys(all_pages))
        return sorted(unique_pages), all_page_info
    
    else:
        # pdf_bytesê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ê²°ê³¼ ë°˜í™˜
        return [], {}